\subsection{Problem}
It is customary to implement cross validation for premise selection in the following manner:
Construct a poset of terms from $T$ using the dependency relation for $x, y \in T$:
\[
	x <_D y ~~\leftrightarrow~~ D^*_x \cap (P^*_y \cup \{y\}) \neq \emptyset
\]

A linearized list constructed from this poset, and each element is:
\begin{itemize}
\item Tested, i.e. treated as a conjecture.
	The classifier is asked for a prediction, and the performance is recorded.
\item Learned to the classifier (added to the trainingset and added to the allowed set of dependencies)
\end{itemize}

Currently, the classifier is trained using the entire trainingset of the fold, without the dependencies of the term-turned-conjecture $\phi$:
\[
	T' = T \setminus D^*_\phi ~\text{and}~ D' = D \setminus D^*_\phi
\]

Using the customary approach, always an equal or better performance is reached.
Trivially this can be concluded because some of the irrelevant terms are excluded from the trainingset, as a result of the poset linearization.
