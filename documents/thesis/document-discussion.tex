\subsection{Problem}
It is customary to implement cross validation for premise selection in the following manner:
Construct a poset of terms from $\terms$ using the dependency relation for $x, y \in \terms$:
\[
	x <_D y ~~\leftrightarrow~~ \depstrans[x] \cap (\parentstrans[y] \cup \{y\}) \neq \emptyset
\]

A linearized list constructed from this poset, and each element is
	first tested, i.e. treated as a conjecture.
	The classifier is asked for a prediction, and the performance is recorded.
	Finally the element is learned to the classifier (added to the trainingset and added to the allowed set of dependencies)

Currently, the classifier is trained using the entire trainingset of the fold, without the dependencies of the term-turned-conjecture $\phi$:
\[
	\trainset' = \trainset \setminus \depstrans[\phi] ~\text{and}~ \deps' = \deps \setminus \depstrans[\phi]
\]

Using the customary approach, always an equal or better performance is reached.
Trivially this can be concluded because some of the irrelevant terms are excluded from the trainingset, as a result of the poset linearization.
