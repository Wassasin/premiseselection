The premise selection tool works as follows, and can be summarised as in table \ref{table:transformations}:
\begin{itemize}
    \item Export all \coq objects from the standard library and the selected corpora to XML.
		\coq has an XML export functionality built in, until version 8.4pl5.
	\item Parse these objects back into canonical \acic format.
	\item From each Coq term $s$ of the form $\hname :\equiv \body : \type$, yield a summary $<\cname[s], \body[s], \type[s]>$:
		where $\hname[s]$ is the human readable term as written in the Coq source file, $\cname[s]$ is the canonical name (uri) of the term,
		$\body[s]$ the names of all objects in the proof body (the proof itself),
		and $\type[s]$ all names in the type of the proof (what is proven).
		These canonical names are not yet human readable as they are composed of internal identifiers.
		Therefore we separately yield a mapping $\cname[s] \rightarrow \cname[s]'$, where $\cname[s]'$ is a human readible canonical name for the term.
		
		In later stages we want to identify these sets by both the Coq term $s$, by the preliminary canonical name $\cname[s]$ and by the eventual human
		readable name $\cname[s]'$.
		Thus in this thesis these identifiers are used interexchangably.
		However in the implementation of \roerei this distinction is relevant.
	\item These summaries are written to disk, and read again in the next half of the pipeline due to problems as described in section \ref{section:report}.
	\item Distinguish theorems from other definitions, which yields the features and dependencies.
		For this I use a heuristic as defined by Kaliszyk \cite{kaliszyk2014machine}:
		the set of allowed features follows directly from splitting the set of all objects into either theorems $\thms$ or definitions $\defs$.
		Were we consider $S$ to be the set of all proven coq terms, we consider
		$$\defs = \bigcup_{s \in S} \type[s] ~~\text{and}~~ \thms = (\bigcup_{s \in S} \body[s]) \setminus \defs \text{.}$$
		This is more extensively explained in section \ref{section:features}.
    \item Generate a \dagraph of dependencies for all \coq objects.
		This is especially useful when determining the performance of our solution as our predictions may not use
		knowledge from future (yet unproven) proofs.
	\item These features and dependencies can now be used to predict, using for example \knn.
	\item Predictions are subsequently augmented by further traversing the \dagraph of dependencies.
\end{itemize}

The implementation of the tools and the subsequent comparison is done using the following steps in the following order, and can be summarised as in table \ref{table:approach}:
\begin{itemize}
	\item Implemented base premise selection tool.
	\item Implemented various performance metrics, as described by Kaliszyk \cite{kaliszyk2014machine}.
	\item Implemented \crossvalidation in order to make proper performance analysis.
    \item Select and perhaps combine various \machinelearning methods, such as \nb or \ensemble.
	\item Select and extract various other features, such as number of conjunctions.
    \item Analyse which combination of features and \machinelearning methods work best for which corpus, and how well these configurations generalize.
\end{itemize}

The selection of features and \machinelearning techniques will occur during the research itself.
The corpora used are determined beforehand.

\begin{figure}[H]
	\centering
	\begin{tikzpicture}[auto, node distance=2.5cm, main/.style={draw,align=center}]
		\node[main] (coq) {Coq term\\inside coq};
		\node[main] (xml) [below of=coq] {XML\\representation};
		\node[main] (term) [below of=xml] {Coq term $s$\\$\cname :\equiv \body : \type$};
		\node[main] (summary) [below of=term] {Summary\\$<\cname[s], \body[s], \type[s], \ldots>$};
		\node[main] (mapping) [left=1cm of summary] {Mapping\\$\cname \rightarrow \cname'$};
		\node[main] (definitions) [below right=2cm and -1cm of summary] {Definitions\\$\defs$};
		\node[main] (additional) [right=1cm of definitions] {Additional\\metrics};
		\node[main] (theorems) [below left=2cm and 0cm of summary] {Theorems\\$\thms$};
		\node[main] (features) [below of=definitions] {Features\\of theorems\\$\features$};
		\node[main] (dependencies) [below of=theorems] {Dependencies\\of theorems\\$\deps$};
		\node[main] (prediction) [below left=1.5cm and -0.1cm of features] {Prediction};

		\draw[->] (coq) edge node {Coq XML export} (xml);
		\draw[->] (xml) edge node {Parser} (term);
		\draw[->] (term) edge node {Resolver} (summary);
		\draw[->] (term) edge node {} (mapping);
		\draw[->] (mapping) edge node {} (summary);
		\draw[->] (summary) edge node [right] {$\type[s]$} (definitions);
		\draw[->] (summary) edge [bend left] node {$\ldots$} (additional);
		\draw[->] (summary) edge node [left] {$\body[s] \setminus \defs$} (theorems);
		\draw[dashed] (definitions) edge node {} (theorems);
		\draw[->] (theorems) edge node {} (dependencies);
		\draw[->] (features) edge node {(External) learner} (prediction);
		\draw[->] (dependencies) edge node {} (prediction);
		\draw[->] (definitions) edge node [above] {} (features);
		\draw[->] (additional) edge node [above] {} (features);
	\end{tikzpicture}
	\label{table:transformations}
	\caption{Transformations performed by the \premiseselection tooling.}
\end{figure}


\subsection{Tooling}
Various design goals of the \premiseselection tool called \roerei are to:
\begin{itemize}
    \item Support offline learning and analysis of \machinelearning on the various corpora.
    \item Enable integration in the \coqide GUI.
    	I would like to create something like Clippy or Vigor for \coq.
    \item Enable merging of the premise selection tool in the \coq main branch as a plugin.
\end{itemize}
In order to achieve this \roerei is implemented on top of the \acic datastructures as exported by the \xml plugin in \coq.
As far as reasonable the \premiseselection tooling is written in \cpp, with the parser and resolver written in \ocaml.
The \machinelearning field favours \python and \matlab as the preferred development environments.
Ideally the tooling created can be used as a building block in a future \coq tactic which finishes proofs fully automatically.

\subsection{Extraction}
The \coq XML plugin exports various objects.
After parsing the XML output only some of these constructs are used.
Of these, the following \coq objects are used:
\begin{description}
    \item[(Co)Inductive definitions]
        \coq allows for (co)inductive definitions.
        These definitions are composed of a name, a type, and a list of constructors.
        Each constructor also is composed of a name and a type.
        A constructor is a valid definition which can be used in theorems.
		A (Co)Inductive definition also yields an induction principle (\texttt{ind}) and a recursion scheme (\texttt{rec}).
		These are also separately exported by \coq, and thus need not be considered further.

    \item[Constants (definitions / theorems / axioms)]
        The types and bodies of constants are defined separately, as needed.
        Theorems are proof-irrelevant, whilst definitions need to be substituted when applied.
        These objects they become undistinguishable when exported.
        Axioms only generate a type, and no body.
\end{description}

The following objects are not used, but could be useful in future work:
\begin{description}
    \item[Proof in progress]
        Consists of a name, a type, a body and a list of dependencies.
        These dependencies still need to be satisfied to complete the proof.
    \item[Tactics application]
        On a higher level, tactics can be applied in order to form a proof.
        These higher level constructs are dependant on the proof engine.
        A proof consisting of tactics can thus become invalid given another \coq version.
        For premise selection these tactics can help solve proofs more quickly, because the proofs they form are smaller.
\end{description}

\coq also exports variables, but these are not used.
A variable consists of a name and a type, and becomes a parameter when a theory which uses the variable is applied.
Thusfar there is no use for these variables within this project.

\subsection{Features and output}
\label{section:features}
When performing \premiseselection, only theorems are regarded.
For other definitions selecting premises is conceptually problematic.
As the training set, for each proven theorem the features are computed from the type.
The definitions used in the body of a theorem are the desired result of the \premiseselection.
Hence, given the type of a new theorem to be proved, the \premiseselection yields a set of definitions which are likely to help prove the theorem.
These definitions are ordered by the chance the definition can be used in the proof.
This ordering is derived from the used definitions of similar complete theorems.
The similarity of complete theorems is captured in the model employed in the \premiseselection, and is derived from the features.

Distinguishing theorems from other definitions is not trivial.
Normally only definitions of kind \prop need to be considered as theorems.
However in the case of \corn the propositions are of type \cprop, which is of kind \kindtype.
Also the kind of a definition is not exported consistently by \coq \citationeeded.
Instead I will initially use a heuristic as defined by Kaliszyk \cite{kaliszyk2014machine}.
This heuristic defines the theorems, or the set of allowed dependencies, as all definitions except those used in the types of definitions.

For \roerei only the definitions used in the theorem type are regarded as features.
Concretely, for a set of proven theorems $S$ with their types and bodies, the used definitions from the types are collected.
From this for each proven theorem $s$ a function $\features[s]$ is defined on the set of allowed features $Z$.
$Z$ is composed of the definitions $\defs$ as well as various other metrics which have been added halfway through this thesis such as the number of conjunctions in the type of a term.
$$ Z = \defs \cup \{ \wedge \} $$
$$
\begin{array}{lcl}
	\features[s] & : & \featurekeys \rightarrow \mathbb{R} \\
	\features[s](x) & = & \left\{
		\begin{array}{ll}
			\counttype{s}{x} & x \in \defs \\
			\counttype{s}{\wedge} & x = \wedge
		\end{array} \right.
\end{array}
$$
For the body of each proven theorem the used definitions are similarly collected, and the set of allowed dependencies $\deps[s]$ is constructed.

The predictor can now, for a unproven theorem, compute the features from the type and yield the ordered set of definitions likely to be useful in the to be constructed body.
After the prototype is completed additional features will be considered and implemented.
Most notably some corpus specific features will be tried.

\subsection{Machine learning}

\subsubsection{\knn}
$$ \text{dist}(x, y) = \left( \sum_{i \in \featurekeys} \left( \features[x](i) - \features[y](i) \right)^2 \right)^{\frac{1}{2}} $$

For each conjecture $c \in \testset$ the distance is computed with each term $t \in \trainset$.
Then the closest $K$ terms $t$ are selected, which we call $\text{closest}_K(c)$.
Their dependencies $\phi \in \deps[t]$ are then suggested; the likelyhood dependant on the distance of their parents to conjecture $c$.
\[ r_\text{knn}(\phi, c) = \sum_{t \in \text{closest}_K(c)} \countbody{t}{\phi} \times \text{dist}(c, t) \]

\subsubsection{\nb}

Given dependency candidate $\phi$, we compute for all features $x \in \featurekeys$:
\[
	w_x = \tau + \sum_{\psi \in \parents[\phi]} \features[\psi](x) ~~\text{with}~~ W = \tau + \sum_{x \in \featurekeys} w_x - \tau
\]

Now we can compute the likelyhood of candidate $\phi$ given some constants $\pi, \sigma, \tau$:
\[
	r_\text{nb}(\phi, c) = \ln W +
	\sum_{x | w_x = 0} \features[c](x) \times \sigma +
	\sum_{x | w_x \neq 0} \features[c](x) \times \ln(\pi \times w_t) - \ln(W)
\]

By K\"uhlwein \cite{kuhlwein2013mash} it is suggested to use $\pi = 10$, $\sigma = -15$ and $\tau = 20$.

\subsection{Example}
\begin{lstlisting}[language=Coq, mathescape]
Inductive nat : Set :=
  | O : nat
  | S : nat -> nat.

Definition nat_id := $\ldots$ .

Fixpoint plus (n m : nat) : nat :=
  match n with
  | O => m
  | S p => S (p + m)
  end.

Lemma plus_0_r : $\forall$ x , plus x 0 = x.
Proof.
$\ldots$ nat_ind $\ldots$
Qed.
Definition plus_0_r n := eq_sym (nat_ind _ eq_refl $\ldots$ ).
\end{lstlisting}

\begin{lstlisting}[language=Coq, mathescape, frame=none]
$S = \{$
	nat : Set$,$
	O : nat$,$
	S : nat -> nat$,$
	nat_ind : $\forall$ P : nat -> Prop, P 0 -> ($\forall$ n : nat, P n -> P (S n)) -> $\forall$ n : nat, P n := fix $\ldots$$,$
	plus : nat -> nat -> nat := fix $\ldots$$,$
	plus_0_r : $\forall$ x , plus x 0 = x := $\ldots$ nat_ind $\ldots$ $,$
$\} $
\end{lstlisting}

\begin{lstlisting}[language=Coq, mathescape, frame=none]
$\defs = \{$nat$,$ 0$,$ S$,$ plus$\}$
\end{lstlisting}

\begin{lstlisting}[language=Coq, mathescape, frame=none]
$\thms = \mathtt{dom}(S) \setminus \defs = \{$nat_ind$,$ plus_0_r$\}$
\end{lstlisting}

\subsection{Corpora}
\begin{description}
    \item[\compcert]
    \item[\formalin]
    \item[\corn]
    \item[\mathcomp]
\end{description}

\subsection{Metrics}
The performance of a predictor is measured using 

\begin{definition}{100Cover}
\end{definition}

\begin{definition}{100Precision}
\end{definition}

\begin{definition}{Recall}
\end{definition}

\begin{definition}{Rank}
\end{definition}

\begin{definition}{Area Under Curve (AUC)}
\end{definition}

% Cross validation on Corpora
% `Proof in Progress` -> step (aconstr)
% Subset corpora (Train) -> Corpus (Test) -> Rating
% A corpus is divided into Proofs in Progress (each substep)
% Ratio of guessed steps 
